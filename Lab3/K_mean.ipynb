{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Invalid alias: The name clear can't be aliased because it is another magic command.\n",
      "ERROR:root:Invalid alias: The name more can't be aliased because it is another magic command.\n",
      "ERROR:root:Invalid alias: The name less can't be aliased because it is another magic command.\n",
      "ERROR:root:Invalid alias: The name man can't be aliased because it is another magic command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Size: (252, 7)\n",
      "   Longitudinal   PrisCof  LDRatio  BDRatio   LBRatio      FNum  RResistance\n",
      "0      0.964286  0.542857     0.55     3.99  0.483516  0.000000     0.001602\n",
      "1      0.964286  0.542857     0.55     3.99  0.483516  0.076923     0.004166\n",
      "2      0.964286  0.542857     0.55     3.99  0.483516  0.153846     0.007371\n",
      "3      0.964286  0.542857     0.55     3.99  0.483516  0.230769     0.012338\n",
      "Iteration Number: 1\n",
      "Error: 196.17247955251395 Squared Error: 180.27823711994282\n",
      "Iteration Number: 2\n",
      "Error: 162.147174883982 Squared Error: 113.93917765438165\n",
      "Iteration Number: 3\n",
      "Error: 160.52159550828824 Squared Error: 111.70881611727881\n",
      "Iteration Number: 4\n",
      "Error: 160.18231765053048 Squared Error: 111.28804031473784\n",
      "Iteration Number: 5\n",
      "Error: 159.93529192162947 Squared Error: 110.98069013134878\n",
      "Iteration Number: 6\n",
      "Error: 159.85069542025903 Squared Error: 110.83304516648916\n"
     ]
    }
   ],
   "source": [
    "%reset\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from matplotlib import pyplot as plt\n",
    "random.seed(5)\n",
    "\n",
    "def getData(dataset_name):\n",
    "    attribute_file_name = 'Data/'+dataset_name+\".attribute\"\n",
    "    dataset_file_name = 'Data/'+dataset_name+\".data\"\n",
    "    att = pd.read_csv(attribute_file_name,\n",
    "                      delim_whitespace=True,\n",
    "                     header = None)\n",
    "    attributes = {rows[0]:rows[1] for _,rows in att.iterrows()}\n",
    "    dataset = pd.read_csv(dataset_file_name, sep=' ',\n",
    "                      names=list(attributes.keys()))\n",
    "    if 'class' in attributes: \n",
    "        del attributes['class']; del dataset['class']\n",
    "    return attributes, dataset\n",
    "\n",
    "\n",
    "\n",
    "def dist(x1,x2, minkowski = 2):\n",
    "    val = 0.0\n",
    "#     print(\"In error: \",attributes)\n",
    "    for att in attributes:\n",
    "        if attributes[att]=='value':\n",
    "            val += (x1[att] - x2[att])*(x1[att] - x2[att])\n",
    "    val = math.sqrt(val)\n",
    "    return val\n",
    "\n",
    "def calculateError():\n",
    "    error = 0\n",
    "    sqrt_error = 0\n",
    "    for i in range(len(dataset)):\n",
    "        sqrt_error += dist(dataset.iloc[i], pd.DataFrame(centroids[cluster_index[i]],index=[0]))**2\n",
    "        error += dist(dataset.iloc[i], pd.DataFrame(centroids[cluster_index[i]],index=[0]))\n",
    "    print(\"Error:\",error,\"Squared Error:\", sqrt_error)\n",
    "    return sqrt_error\n",
    "\n",
    "def assignCluster():\n",
    "    flag = False\n",
    "    for i in range(len(dataset)):\n",
    "        min_val = math.inf\n",
    "        min_idx = -1\n",
    "        for j in range(len(centroids)):\n",
    "            distance = dist(dataset.iloc[i], pd.DataFrame(centroids[j],index=[0]))\n",
    "            if distance < min_val:\n",
    "                min_val = distance\n",
    "                min_idx = j\n",
    "        if flag==False and cluster_index[i] != min_idx:\n",
    "            print\n",
    "            flag = True\n",
    "        cluster_index[i] = min_idx\n",
    "    return flag\n",
    "\n",
    "def newCentroids():\n",
    "    for i in range(len(centroids)):\n",
    "        List = [j for j in range(len(dataset)) if cluster_index[j]==i]\n",
    "#         print(\"Len:\",len(List))\n",
    "        clustered_data = dataset.iloc[List]\n",
    "        if (len(clustered_data)>0):\n",
    "            for column in dataset.columns:\n",
    "                centroids[i][column] = clustered_data[column].mean()\n",
    "\n",
    "\n",
    "def showGraph(loop_num):\n",
    "    x = []\n",
    "    y = []\n",
    "    color = [\"red\",\"green\", \"blue\", \"yellow\", \"black\"]\n",
    "    for i in range(len(centroids)+1):\n",
    "        x.append([])\n",
    "        y.append([])\n",
    "    for i in range(len(dataset)):\n",
    "        x[cluster_index[i]].append(dataset.iloc[i]['x'])\n",
    "        y[cluster_index[i]].append(dataset.iloc[i]['y'])\n",
    "    for i in range(len(centroids)):\n",
    "        x[len(centroids)].append(centroids[i]['x'])\n",
    "        y[len(centroids)].append(centroids[i]['y'])\n",
    "    for i in range(len(centroids)):\n",
    "        plt.scatter(x[i],y[i],color=color[i])\n",
    "    print(\"Centroids: \")\n",
    "    print(x[-1],y[-1])\n",
    "    \n",
    "    plt.scatter(x[-1],y[-1],color=\"black\")\n",
    "    filename = \"fig_\"+str(loop_num)+\".png\"\n",
    "#     print(filename)\n",
    "    plt.savefig(filename)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "dataset_name = 'yacht_hydrodynamics'\n",
    "k = 3\n",
    "\n",
    "attributes, dataset = getData(dataset_name)\n",
    "dataset = dataset.dropna()\n",
    "print(\"Dataset Size:\",dataset.shape)\n",
    "min_max_scaler = MinMaxScaler()\n",
    "value_attributes = [key for key,value in attributes.items() if value=='value']\n",
    "dataset[value_attributes] = min_max_scaler.fit_transform(dataset[value_attributes])\n",
    "\n",
    "print(dataset.head(4))\n",
    "\n",
    "centroids = []\n",
    "cluster_index = [-1]*len(dataset)\n",
    "# print(cluster_index)\n",
    "for i in range (k): \n",
    "    centroid = {}\n",
    "    random_number = random.randint(0,len(dataset))\n",
    "    for column in dataset.columns:\n",
    "        centroid[column] = dataset.iloc[random_number][column]\n",
    "    centroids.append(centroid)\n",
    "loop_num = 0\n",
    "\n",
    "\n",
    "\n",
    "while True:\n",
    "    loop_num += 1\n",
    "    continue_loop = assignCluster()\n",
    "#     print(cluster_index)\n",
    "#     showGraph(loop_num)\n",
    "    print(\"Iteration Number:\",loop_num)\n",
    "    newError = calculateError()\n",
    "    newCentroids()\n",
    "    if continue_loop == False or loop_num>20:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.iloc[[1,2,4,10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(math.inf>=100000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.iloc[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
