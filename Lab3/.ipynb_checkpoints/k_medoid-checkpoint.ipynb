{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Invalid alias: The name clear can't be aliased because it is another magic command.\n",
      "ERROR:root:Invalid alias: The name more can't be aliased because it is another magic command.\n",
      "ERROR:root:Invalid alias: The name less can't be aliased because it is another magic command.\n",
      "ERROR:root:Invalid alias: The name man can't be aliased because it is another magic command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Size: (100, 2)\n",
      "          x         y\n",
      "0  0.191885  0.174697\n",
      "1  0.027076  0.098719\n",
      "2  0.117530  0.209008\n",
      "3  0.173476  0.075840\n"
     ]
    }
   ],
   "source": [
    "%reset\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from matplotlib import pyplot as plt\n",
    "random.seed(5)\n",
    "\n",
    "def getData(dataset_name):\n",
    "    attribute_file_name = 'Data/'+dataset_name+\".attribute\"\n",
    "    dataset_file_name = 'Data/'+dataset_name+\".data\"\n",
    "    att = pd.read_csv(attribute_file_name,\n",
    "                      delim_whitespace=True,\n",
    "                     header = None)\n",
    "    attributes = {rows[0]:rows[1] for _,rows in att.iterrows()}\n",
    "    dataset = pd.read_csv(dataset_file_name,\n",
    "                      names=list(attributes.keys()))\n",
    "    if 'class' in attributes: \n",
    "        del attributes['class']; del dataset['class']\n",
    "    return attributes, dataset\n",
    "\n",
    "\n",
    "def dist(x1,x2, minkowski = 2):\n",
    "    val = 0.0\n",
    "#     print(\"In error: \",attributes)\n",
    "    for att in attributes:\n",
    "        if attributes[att]=='value':\n",
    "            val += (x1[att] - x2[att])*(x1[att] - x2[att])\n",
    "    val = math.sqrt(val)\n",
    "    return val\n",
    "\n",
    "def calculateError(curr_centroids):\n",
    "    error = 0\n",
    "    sqrt_error = 0\n",
    "    for i in range(len(dataset)):\n",
    "        sqrt_error += dist(dataset.iloc[i], pd.DataFrame(curr_centroids[cluster_index[i]],index=[0]))**2\n",
    "        error += dist(dataset.iloc[i], pd.DataFrame(centroids[curr_centroids[i]],index=[0]))\n",
    "    print(\"Error:\",error,\"Squared Error:\", sqrt_error)\n",
    "    return sqrt_error\n",
    "\n",
    "\n",
    "def assignCluster():\n",
    "    flag = False\n",
    "    for i in range(len(dataset)):\n",
    "        min_val = math.inf\n",
    "        min_idx = -1\n",
    "        for j in range(len(centroids)):\n",
    "            distance = dist(dataset.iloc[i], pd.DataFrame(centroids[j],index=[0]))\n",
    "            if distance < min_val:\n",
    "                min_val = distance\n",
    "                min_idx = j\n",
    "        if flag==False and cluster_index[i] != min_idx:\n",
    "            print\n",
    "            flag = True\n",
    "        cluster_index[i] = min_idx\n",
    "    return flag\n",
    "\n",
    "dataset_name = 'test'\n",
    "k = 3\n",
    "\n",
    "attributes, dataset = getData(dataset_name)\n",
    "dataset = dataset.dropna()\n",
    "print(\"Dataset Size:\",dataset.shape)\n",
    "min_max_scaler = MinMaxScaler()\n",
    "value_attributes = [key for key,value in attributes.items() if value=='value']\n",
    "dataset[value_attributes] = min_max_scaler.fit_transform(dataset[value_attributes])\n",
    "\n",
    "centroids = []\n",
    "cluster_index = [-1]*len(dataset)\n",
    "# print(cluster_index)\n",
    "for i in range (k): \n",
    "    centroid = {}\n",
    "    random_number = random.randint(0,len(dataset))\n",
    "    for column in dataset.columns:\n",
    "        centroid[column] = dataset.iloc[random_number][column]\n",
    "    centroids.append(centroid)\n",
    "\n",
    "\n",
    "print(dataset.head(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
