{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Invalid alias: The name clear can't be aliased because it is another magic command.\n",
      "ERROR:root:Invalid alias: The name more can't be aliased because it is another magic command.\n",
      "ERROR:root:Invalid alias: The name less can't be aliased because it is another magic command.\n",
      "ERROR:root:Invalid alias: The name man can't be aliased because it is another magic command.\n",
      "/home/ahasan/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:334: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: ILPD\n",
      "Dataset Size: (579, 9)\n",
      "K: 2\n",
      "_______________________  Instance: 0 _____________________\n",
      "Iteration 1 Error:  199.07348317990838\n",
      "Iteration 2 Error:  188.0135734243015\n",
      "Iteration 3 Error:  181.67618561017986\n",
      "Iteration 4 Error:  179.55461391448165\n",
      "Average of Variance and Silhouette Coefficient\n",
      "179.55461391448165,0.24163979026389343\n",
      "BCubed Precision : 0.5910097429159333 , Recall : 0.4978361083731289\n",
      "BCubed precision: 0.5910097429159333 BCubed Recall: 0.4978361083731289\n",
      "_______________________  Instance: 1 _____________________\n",
      "Iteration 1 Error:  211.4595089874295\n",
      "Iteration 2 Error:  187.3116444714644\n",
      "Iteration 3 Error:  181.8804330410643\n",
      "Iteration 4 Error:  179.34559396642322\n",
      "Average of Variance and Silhouette Coefficient\n",
      "179.45010394045244,0.24400558260662253\n",
      "BCubed Precision : 0.5911091661647723 , Recall : 0.5074085338688886\n",
      "BCubed precision: 0.5910594545403528 BCubed Recall: 0.5026223211210088\n",
      "_______________________  Instance: 2 _____________________\n",
      "Iteration 1 Error:  272.19452313175384\n",
      "Iteration 2 Error:  203.21516594029902\n",
      "Iteration 3 Error:  186.1255088838943\n",
      "Iteration 4 Error:  180.53155678912344\n",
      "Iteration 5 Error:  179.2353227280634\n",
      "Average of Variance and Silhouette Coefficient\n",
      "179.37851020298942,0.24451820406535718\n",
      "BCubed Precision : 0.591041097437943 , Recall : 0.49680767500471174\n",
      "BCubed precision: 0.5910533355062162 BCubed Recall: 0.5006841057489098\n",
      "_______________________  Instance: 3 _____________________\n",
      "Iteration 1 Error:  239.28738427140786\n",
      "Iteration 2 Error:  213.01331285007586\n",
      "Iteration 3 Error:  186.381394022338\n",
      "Iteration 4 Error:  181.90492813009\n",
      "Iteration 5 Error:  181.26036588968927\n",
      "Average of Variance and Silhouette Coefficient\n",
      "179.84897412466438,0.23830805070842936\n",
      "BCubed Precision : 0.5925189124715207 , Recall : 0.4984962070677291\n",
      "BCubed precision: 0.5914197297475423 BCubed Recall: 0.5001371310786146\n",
      "_______________________  Instance: 4 _____________________\n",
      "Iteration 1 Error:  212.41353898424816\n",
      "Iteration 2 Error:  203.01053001611086\n",
      "Iteration 3 Error:  181.344231993089\n",
      "Average of Variance and Silhouette Coefficient\n",
      "180.1480256983493,0.23839147008283226\n",
      "BCubed Precision : 0.5909954420796888 , Recall : 0.509383758389953\n",
      "BCubed precision: 0.5913348722139716 BCubed Recall: 0.5019864565408823\n",
      "Average of Variance and Silhouette Coefficient over 5 iteration\n",
      "180.1480256983493,0.23839147008283226\n"
     ]
    }
   ],
   "source": [
    "%reset\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import copy\n",
    "from statistics import mean \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import  silhouette_score\n",
    "from matplotlib import pyplot as plt\n",
    "# random.seed(5)\n",
    "%matplotlib inline\n",
    "\n",
    "def getData(dataset_name):\n",
    "    attribute_file_name = 'Data/'+dataset_name+\".attribute\"\n",
    "    dataset_file_name = 'Data/'+dataset_name+\".data\"\n",
    "    att = pd.read_csv(attribute_file_name,\n",
    "                      delim_whitespace=True,\n",
    "                     header = None)\n",
    "    attributes = {rows[0]:rows[1] for _,rows in att.iterrows()}\n",
    "    dataset = pd.read_csv(dataset_file_name,\n",
    "                      names=list(attributes.keys()))\n",
    "    if 'class' in attributes: \n",
    "        tuple_labels = []\n",
    "        label_count = []\n",
    "        classes = {}\n",
    "        tuple_labels = list(dataset[\"class\"])\n",
    "        classes_unique, label_count = np.unique(tuple_labels, return_counts=True)\n",
    "        idx = 0\n",
    "        for class_ in classes_unique:\n",
    "            classes[class_] = idx\n",
    "            idx += 1\n",
    "#         print(classes)\n",
    "        del attributes['class']; del dataset['class']\n",
    "    return  dataset,classes,tuple_labels,label_count\n",
    "\n",
    "\n",
    "\n",
    "def dist(x1,x2, minkowski = 2):\n",
    "    val = 0.0\n",
    "#     print(\"In error: \",attributes)\n",
    "    for att in attributes:\n",
    "#         if attributes[att]=='value':\n",
    "        val += (x1[att] - x2[att])*(x1[att] - x2[att])\n",
    "    val = math.sqrt(val)\n",
    "    return val\n",
    "\n",
    "\n",
    "def assignCluster(curr_centroid_index):\n",
    "    new_cluster_index = [-1]*len(dataset)\n",
    "    total_error = 0\n",
    "#     flag = False\n",
    "    for i in range(len(dataset)):\n",
    "        min_val = math.inf\n",
    "        min_idx = -1\n",
    "        for j in range(len(curr_centroid_index)):\n",
    "            distance = dist(dataset.iloc[i],dataset.iloc[curr_centroid_index[j]])\n",
    "            if distance < min_val:\n",
    "                min_val = distance\n",
    "                min_idx = j\n",
    "        new_cluster_index[i] = min_idx\n",
    "        total_error += abs(min_val)\n",
    "    return new_cluster_index, total_error\n",
    "\n",
    "def bcubed():\n",
    "    if len(classes) == 0:\n",
    "        print(\"no labels\")\n",
    "        return\n",
    "    cluster_label_combo = np.zeros([len(centroid_index), len(classes)])\n",
    "    cluster_count = np.zeros([len(centroid_index)])\n",
    "    for i in range(len(dataset)):\n",
    "        cluster_label_combo[cluster_index[i]][classes[tuple_labels[i]]] += 1.0\n",
    "        cluster_count[cluster_index[i]] += 1.0\n",
    "\n",
    "    bcp = 0.0\n",
    "    bcr = 0.0\n",
    "    for i in range(len(dataset)):\n",
    "        bcp += cluster_label_combo[cluster_index[i]][classes[tuple_labels[i]]]/cluster_count[cluster_index[i]]\n",
    "        bcr += cluster_label_combo[cluster_index[i]][classes[tuple_labels[i]]]/label_count[classes[tuple_labels[i]]]\n",
    "    bcp /= len(dataset)\n",
    "    bcr /= len(dataset)\n",
    "    print(\"BCubed Precision :\", bcp, \", Recall :\", bcr)\n",
    "    return bcp,bcr\n",
    "\n",
    "\n",
    "def showGraph(loop_num):\n",
    "    x = []\n",
    "    y = []\n",
    "    color = [\"red\",\"green\", \"blue\", \"yellow\", \"black\"]\n",
    "    for i in range(len(centroid_index)+1):\n",
    "        x.append([])\n",
    "        y.append([])\n",
    "    for i in range(len(dataset)):\n",
    "        x[cluster_index[i]].append(dataset.iloc[i]['x'])\n",
    "        y[cluster_index[i]].append(dataset.iloc[i]['y'])\n",
    "    for i in range(len(centroid_index)):\n",
    "        x[len(centroid_index)].append(dataset.iloc[centroid_index[i]]['x'])\n",
    "        y[len(centroid_index)].append(dataset.iloc[centroid_index[i]]['y'])\n",
    "    for i in range(len(centroid_index)):\n",
    "        plt.scatter(x[i],y[i],color=color[i])\n",
    "    print(\"Centroids: \")\n",
    "    \n",
    "    plt.scatter(x[-1],y[-1],color=\"black\")\n",
    "    filename = \"fig_\"+str(loop_num)+\".png\"\n",
    "    plt.savefig(filename)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "dataset_name = 'ILPD'\n",
    "k = 2\n",
    "groundTruth = True\n",
    "if groundTruth:\n",
    "    dataset,classes,tuple_labels,label_count = getData(dataset_name)\n",
    "    bcp = []\n",
    "    bcr = []\n",
    "else:\n",
    "    filepath=\"Data/\"+dataset_name+\".data\"\n",
    "    dataset = pd.read_csv(filepath)\n",
    "    \n",
    "dataset = dataset.dropna()\n",
    "print(\"Dataset:\",dataset_name)\n",
    "print(\"Dataset Size:\",dataset.shape)\n",
    "print(\"K:\",k)\n",
    "min_max_scaler = MinMaxScaler()\n",
    "value_attributes = list(dataset.columns)\n",
    "attributes = list(dataset.columns)\n",
    "dataset[value_attributes] = min_max_scaler.fit_transform(dataset[value_attributes])\n",
    "\n",
    "silhouette_avg=[]\n",
    "variance = []\n",
    "for _ in range(5):\n",
    "    print(\"_______________________  Instance:\",_,\"_____________________\")\n",
    "    centroid_index=random.sample(range(0,len(dataset)),k)\n",
    "    cluster_index, total_error = assignCluster(centroid_index)\n",
    "    L = 0\n",
    "    while L<10:\n",
    "        L +=1\n",
    "        print(\"Iteration\",L,\"Error: \",total_error)\n",
    "#         print()\n",
    "    #     showGraph(L)\n",
    "        Flag = False\n",
    "        prev_centroid_index = copy.deepcopy(centroid_index)\n",
    "        for i in range(k):\n",
    "            for j in random.sample(range(1,len(dataset)),int(len(dataset)*0.2)):\n",
    "                if i==j: continue\n",
    "                new_centroid_index = copy.deepcopy(centroid_index)\n",
    "                new_centroid_index[i] = j\n",
    "                new_cluster_index, new_total_error = assignCluster(new_centroid_index)\n",
    "                if (new_total_error < total_error):\n",
    "                    total_error = new_total_error\n",
    "                    cluster_index = copy.deepcopy(new_cluster_index)\n",
    "                    centroid_index = copy.deepcopy(new_centroid_index)\n",
    "                    Flag = True\n",
    "                    break\n",
    "        if Flag==False:\n",
    "            break\n",
    "    silhouette_avg.append(silhouette_score(dataset.values.tolist(),cluster_index))\n",
    "    variance.append(total_error)\n",
    "    print(\"Average of Variance and Silhouette Coefficient\")\n",
    "    print(str(str(mean(variance)))+\",\"+str(mean(silhouette_avg)))\n",
    "    if groundTruth:\n",
    "        precision,recall = bcubed()\n",
    "        bcp.append(precision); bcr.append(recall)\n",
    "        print(\"BCubed precision:\",mean(bcp),\"BCubed Recall:\",mean(bcr))\n",
    "\n",
    "print(\"Average of Variance and Silhouette Coefficient over 5 iteration\")\n",
    "print(str(str(mean(variance)))+\",\"+str(mean(silhouette_avg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"বাংলা\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean \n",
    "abc = [1,2,3,4]\n",
    "print(mean(abc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
